{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "from cl_sster import cl_sster\n",
    "import numpy as np\n",
    "import os\n",
    "import mat73\n",
    "import scipy.io as sio\n",
    "from postprocessing_utils import calc_isc, calc_isc_train\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from postprocessing_utils import plot_dendrogram\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "fs = 128\n",
    "epochs_pretrain = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Data\\Simulation_naturalstimuli\n",
      "[19200 19200 19200 19200 19200 19200 19200 19200 19200 19200 19200 19200\n",
      " 19200 19200 19200 19200 19200 19200 19200 19200]\n",
      "(20, 384000, 128)\n",
      "Normalizing\n"
     ]
    }
   ],
   "source": [
    "# Load simulation data\n",
    "datadir = r'D:\\Data\\Simulation_naturalstimuli'\n",
    "print(datadir)\n",
    "n_points = np.ones(20).astype(int) * 19200\n",
    "print(n_points)\n",
    "\n",
    "data = mat73.loadmat(os.path.join(datadir, 'data_component3_noise2_8.mat'))['data']\n",
    "data = data.transpose(2,0,1)\n",
    "n_subs = data.shape[0]\n",
    "print(data.shape)\n",
    "\n",
    "# Normalization without outliers\n",
    "print('Normalizing')\n",
    "for sub in range(n_subs):\n",
    "    thr = 30 * np.median(abs(data[sub]))\n",
    "    data[sub] = (data[sub] - np.mean(data[sub][data[sub] < thr])) / np.std(data[sub][data[sub] < thr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available: True\n",
      "The results will be saved to: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_all\n",
      "Train with all data\n",
      "data_train.shape, data_val.shape (7680000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.2432665344915894   Top1 accuracy: 66.0657894736842   Top5 accuracy: 77.86842105263158\n",
      "\tVal loss: 0.8799546656086679   Top1 accuracy: 98.62222222222222   Top5 accuracy: 99.94166666666666\n",
      "time consumed: 179.7052104473114\n",
      "Epoch: 1   Train loss: 0.7051140676987798   Top1 accuracy: 99.27631578947368   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5510020069737482   Top1 accuracy: 99.81805555555556   Top5 accuracy: 99.99722222222222\n",
      "time consumed: 160.7772524356842\n",
      "Epoch: 2   Train loss: 0.5067143383779024   Top1 accuracy: 99.86842105263158   Top5 accuracy: 99.97368421052632\n",
      "\tVal loss: 0.4597241870139957   Top1 accuracy: 99.91944444444445   Top5 accuracy: 100.0\n",
      "time consumed: 150.12712359428406\n",
      "Epoch: 3   Train loss: 0.4632323555256191   Top1 accuracy: 99.88157894736842   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4302310987969698   Top1 accuracy: 99.925   Top5 accuracy: 100.0\n",
      "time consumed: 150.51755046844482\n",
      "Epoch: 4   Train loss: 0.46110886225574893   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43907355192240577   Top1 accuracy: 99.90833333333333   Top5 accuracy: 100.0\n",
      "time consumed: 146.579448223114\n",
      "Epoch: 5   Train loss: 0.44932263799403843   Top1 accuracy: 99.92105263157895   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.434148637092208   Top1 accuracy: 99.925   Top5 accuracy: 100.0\n",
      "time consumed: 149.76583790779114\n",
      "Epoch: 6   Train loss: 0.4450769837749632   Top1 accuracy: 99.85526315789474   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42160648591068517   Top1 accuracy: 99.91666666666667   Top5 accuracy: 100.0\n",
      "time consumed: 149.18502736091614\n",
      "Epoch: 7   Train loss: 0.45132463550881335   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42143113347326816   Top1 accuracy: 99.91805555555555   Top5 accuracy: 100.0\n",
      "time consumed: 148.40700602531433\n",
      "Epoch: 8   Train loss: 0.44751025226555374   Top1 accuracy: 99.80263157894737   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.425470593438432   Top1 accuracy: 99.9125   Top5 accuracy: 100.0\n",
      "time consumed: 152.31146883964539\n",
      "Epoch: 9   Train loss: 0.43756908601836153   Top1 accuracy: 99.89473684210526   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4148357744801049   Top1 accuracy: 99.92916666666666   Top5 accuracy: 100.0\n",
      "time consumed: 192.7870659828186\n",
      "Epoch: 10   Train loss: 0.43418508179877935   Top1 accuracy: 99.90789473684211   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4183833536839019   Top1 accuracy: 99.90833333333333   Top5 accuracy: 100.0\n",
      "time consumed: 180.13942050933838\n",
      "Epoch: 11   Train loss: 0.4395986773465809   Top1 accuracy: 99.90789473684211   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41142673059486495   Top1 accuracy: 99.925   Top5 accuracy: 100.0\n",
      "time consumed: 183.66339898109436\n",
      "Epoch: 12   Train loss: 0.43456465507808484   Top1 accuracy: 99.92105263157895   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42109646454175564   Top1 accuracy: 99.90416666666667   Top5 accuracy: 100.0\n",
      "time consumed: 187.45981192588806\n",
      "Epoch: 13   Train loss: 0.4309748284126583   Top1 accuracy: 99.85526315789474   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4173942597066535   Top1 accuracy: 99.9125   Top5 accuracy: 100.0\n",
      "time consumed: 189.06921863555908\n",
      "Epoch: 14   Train loss: 0.4505881641256182   Top1 accuracy: 99.8157894736842   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.413609314049643   Top1 accuracy: 99.925   Top5 accuracy: 100.0\n",
      "time consumed: 191.37123894691467\n",
      "Epoch: 15   Train loss: 0.4358997134785903   Top1 accuracy: 99.9342105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4230881956226333   Top1 accuracy: 99.91805555555555   Top5 accuracy: 100.0\n",
      "time consumed: 174.60322546958923\n",
      "Epoch: 16   Train loss: 0.4400230051655518   Top1 accuracy: 99.84210526315789   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4278127218873174   Top1 accuracy: 99.90555555555555   Top5 accuracy: 100.0\n",
      "time consumed: 152.37117075920105\n",
      "Epoch: 17   Train loss: 0.4359377374774531   Top1 accuracy: 99.88157894736842   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41415022211946256   Top1 accuracy: 99.91666666666667   Top5 accuracy: 100.0\n",
      "time consumed: 150.71323800086975\n",
      "Epoch: 18   Train loss: 0.4403876639510456   Top1 accuracy: 99.90789473684211   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4126079163238359   Top1 accuracy: 99.91388888888889   Top5 accuracy: 100.0\n",
      "time consumed: 151.1648941040039\n",
      "Epoch: 19   Train loss: 0.430969012803153   Top1 accuracy: 99.9342105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40954920793244937   Top1 accuracy: 99.92083333333333   Top5 accuracy: 100.0\n",
      "time consumed: 151.33600759506226\n",
      "Epoch: 20   Train loss: 0.43177940076903293   Top1 accuracy: 99.77631578947368   Top5 accuracy: 99.98684210526316\n",
      "\tVal loss: 0.4472317746576755   Top1 accuracy: 99.88055555555556   Top5 accuracy: 100.0\n",
      "time consumed: 151.701491355896\n",
      "Epoch: 21   Train loss: 0.4368623435497284   Top1 accuracy: 99.85526315789474   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4197223239559783   Top1 accuracy: 99.90833333333333   Top5 accuracy: 100.0\n",
      "time consumed: 151.2760624885559\n",
      "Epoch: 22   Train loss: 0.45083924822117155   Top1 accuracy: 99.71052631578948   Top5 accuracy: 99.9342105263158\n",
      "\tVal loss: 0.408562133363533   Top1 accuracy: 99.92777777777778   Top5 accuracy: 100.0\n",
      "time consumed: 150.3874967098236\n",
      "Epoch: 23   Train loss: 0.4303881359727759   Top1 accuracy: 99.88157894736842   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42036522954220146   Top1 accuracy: 99.9125   Top5 accuracy: 100.0\n",
      "time consumed: 150.8008975982666\n",
      "Epoch: 24   Train loss: 0.4298431142380363   Top1 accuracy: 99.89473684210526   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4118859584133032   Top1 accuracy: 99.91388888888889   Top5 accuracy: 100.0\n",
      "time consumed: 152.3054850101471\n",
      "Epoch: 25   Train loss: 0.4375879047732604   Top1 accuracy: 99.85526315789474   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4156353304639126   Top1 accuracy: 99.91388888888889   Top5 accuracy: 100.0\n",
      "time consumed: 150.0267367362976\n",
      "Epoch: 26   Train loss: 0.4372354227461313   Top1 accuracy: 99.8157894736842   Top5 accuracy: 99.98684210526316\n",
      "\tVal loss: 0.4226897768767392   Top1 accuracy: 99.91388888888889   Top5 accuracy: 100.0\n",
      "time consumed: 146.85241389274597\n",
      "Epoch: 27   Train loss: 0.42927112885211643   Top1 accuracy: 99.88157894736842   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4125868181587723   Top1 accuracy: 99.90972222222223   Top5 accuracy: 100.0\n",
      "time consumed: 146.14694714546204\n",
      "Epoch: 28   Train loss: 0.4334413630397696   Top1 accuracy: 99.90789473684211   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4101043764803378   Top1 accuracy: 99.91805555555555   Top5 accuracy: 100.0\n",
      "time consumed: 145.7854676246643\n",
      "Epoch: 29   Train loss: 0.4435397301065294   Top1 accuracy: 99.89473684210526   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4219866749863488   Top1 accuracy: 99.90972222222223   Top5 accuracy: 100.0\n",
      "time consumed: 146.2368505001068\n",
      "best epoch: 9, train top1 acc:99.895, top5 acc:100.000; val top1 acc:99.929, top5 acc:100.000, train loss:0.4376, val loss: 0.4148\n",
      "train top1 mean: 99.895, train top1 std: 0.000; val top1 mean: 99.929, val top1 std: 0.000\n"
     ]
    }
   ],
   "source": [
    "# Train with all data\n",
    "cl_model_allData = cl_sster(n_folds=1, epochs_pretrain=epochs_pretrain, data_type='simulation') # If n_folds == 1, it will use all data to train the model\n",
    "cl_model_allData.load_data(data, n_points) # fs: sampling rate\n",
    "cl_model_allData.train_cl_sster() # Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_all\\0\\checkpoint_0029.pth.tar\n"
     ]
    }
   ],
   "source": [
    "out, n_points_cum = cl_model_allData.get_hidden(fold=0) # The function will load the trained model and get hidden representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ISC for the model trained with all data\n",
    "out_all_corr_mean = calc_isc_train(out.transpose(2,1,0), n_points_cum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of nonzero dims 256\n"
     ]
    }
   ],
   "source": [
    "# Visualize the hierarchical clustering results\n",
    "nonzero_dims = cl_model_allData.check_nonzero_dims()\n",
    "out_corr_dims_mean = cl_model_allData.calc_out_corr_dims() # Only used nonzero dims here\n",
    "affinity_mat = 1 - np.abs(out_corr_dims_mean)\n",
    "cluster_model = AgglomerativeClustering(distance_threshold=0, n_clusters=None, metric='precomputed', linkage='average')\n",
    "cluster_model = cluster_model.fit(affinity_mat)\n",
    "sio.savemat(os.path.join(cl_model_allData.save_dir, 'nonzero_dims.mat'), {'nonzero_dims': nonzero_dims})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "R = plot_dendrogram(cluster_model, truncate_mode=\"level\", p=15, color_threshold=0.9)\n",
    "plt.xlabel(\"Number of points in node (or index of point if no parenthesis).\")\n",
    "plt.ylim([0,1])\n",
    "plt.savefig(os.path.join(cl_model_allData.save_dir, 'hier_cluster.jpg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inds_reorder = np.zeros(len(R['ivl'])).astype(int)\n",
    "for i in range(len(R['ivl'])):\n",
    "    inds_reorder[i] = int(R['ivl'][i])\n",
    "# print(inds_reorder)\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.imshow(1-affinity_mat[inds_reorder, :][:, inds_reorder])\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig(os.path.join(cl_model_allData.save_dir, 'affinity_mat.jpg'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the clusters \n",
    "cluster_model = AgglomerativeClustering(distance_threshold=0.9, n_clusters=None, metric='precomputed', linkage='average')\n",
    "cluster_model = cluster_model.fit(affinity_mat)\n",
    "c_labels = cluster_model.labels_\n",
    "n_clusters = len(np.unique(c_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79]\n",
      "[0.34053957]\n"
     ]
    }
   ],
   "source": [
    "# Get the diemensions with best ISC in each cluster (trained with all data)\n",
    "isc_mean = np.mean(out_all_corr_mean, axis=1)\n",
    "isc_mean_sel = isc_mean[nonzero_dims]\n",
    "inds_order = np.arange(len(nonzero_dims))\n",
    "inds_cluster_max = np.zeros(n_clusters).astype(int)\n",
    "for i in range(n_clusters):\n",
    "    tmp = np.argmax(isc_mean_sel[c_labels==i])\n",
    "    inds_cluster_max[i] = nonzero_dims[int(inds_order[c_labels==i][tmp])]\n",
    "print(inds_cluster_max)\n",
    "print(isc_mean[inds_cluster_max])\n",
    "sio.savemat(os.path.join(cl_model_allData.save_dir, 'inds_cluster_max.mat'), {'inds_cluster_max':inds_cluster_max})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 temporal: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16]\n",
      "  spatial: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15]\n"
     ]
    }
   ],
   "source": [
    "# See the filter indices in each cluster\n",
    "ts_lists = {}\n",
    "for j in range(n_clusters):\n",
    "    ts_lists[j] = []\n",
    "\n",
    "tree_order = []\n",
    "for i in range(len(R['ivl'])):\n",
    "    ind_now_new = int(R['ivl'][i])\n",
    "    ind_now = nonzero_dims[ind_now_new]\n",
    "    # print(ind_now, c_labels[ind_now_new], ind_now//16+1, np.mod(ind_now+1, 16))\n",
    "    ts_lists[c_labels[ind_now_new]].append([ind_now//16+1, np.mod(ind_now+1,16)])\n",
    "    if c_labels[ind_now_new] not in tree_order:\n",
    "        tree_order.append(c_labels[ind_now_new])\n",
    "    \n",
    "for j in range(n_clusters):\n",
    "    tmp = np.array(ts_lists[tree_order[j]])\n",
    "    print(j, 'temporal:', np.unique(tmp[:,0]))\n",
    "    print('  spatial:', np.unique(tmp[:,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is cuda available: True\n",
      "The results will be saved to: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\n",
      "Conduct cross-validation\n",
      "val sub [0]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.3466267146562276   Top1 accuracy: 63.04093567251462   Top5 accuracy: 76.16959064327486\n",
      "\tVal loss: 0.9227336049079895   Top1 accuracy: 98.46491228070175   Top5 accuracy: 99.91228070175438\n",
      "time consumed: 32.22966289520264\n",
      "Epoch: 1   Train loss: 0.7486588958411189   Top1 accuracy: 99.1374269005848   Top5 accuracy: 99.95614035087719\n",
      "\tVal loss: 0.5662792910609329   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 27.507833242416382\n",
      "Epoch: 2   Train loss: 0.5236828133725283   Top1 accuracy: 99.89766081871345   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.46916802340780783   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 29.266556978225708\n",
      "Epoch: 3   Train loss: 0.484928517749435   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4511589186581952   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 27.97511911392212\n",
      "Epoch: 4   Train loss: 0.4576879077487522   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.422461334899155   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 27.738534450531006\n",
      "Epoch: 5   Train loss: 0.44952612365895545   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43362956873157565   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 27.833664178848267\n",
      "Epoch: 6   Train loss: 0.44819423913607126   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4290382074333771   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 27.837313413619995\n",
      "Epoch: 7   Train loss: 0.4472285391468751   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42853026449331766   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 27.66980290412903\n",
      "Epoch: 8   Train loss: 0.4529823162402326   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.416435894300366   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 27.62761425971985\n",
      "Epoch: 9   Train loss: 0.4444626431193268   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4177486133157161   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 27.126700162887573\n",
      "Epoch: 10   Train loss: 0.44620767444895026   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4188700791513711   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 27.122736930847168\n",
      "Epoch: 11   Train loss: 0.4385188755236174   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42663321561283535   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 28.923081874847412\n",
      "Epoch: 12   Train loss: 0.4383616333293636   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4233053872111248   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 27.60071873664856\n",
      "Epoch: 13   Train loss: 0.4474442826028456   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43420201261141145   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 27.07431983947754\n",
      "Epoch: 14   Train loss: 0.4455806527569977   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4079081659254275   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 27.177568674087524\n",
      "Epoch: 15   Train loss: 0.43165924561302565   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40655348280019926   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 27.17520260810852\n",
      "Epoch: 16   Train loss: 0.4368037195407856   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4074312462444194   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 27.071868658065796\n",
      "Epoch: 17   Train loss: 0.43216570331687815   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4046604020728005   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.933602571487427\n",
      "Epoch: 18   Train loss: 0.4321755196964532   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4063577220628136   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 27.140115976333618\n",
      "Epoch: 19   Train loss: 0.44061015572464257   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4070947539736653   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 27.034063816070557\n",
      "Epoch: 20   Train loss: 0.4379208083564078   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41634968480868645   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 27.32941198348999\n",
      "Epoch: 21   Train loss: 0.43580044344154717   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40799002907080956   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 28.60528039932251\n",
      "Epoch: 22   Train loss: 0.43554059899689856   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4047431813346015   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 28.465672731399536\n",
      "Epoch: 23   Train loss: 0.4404324732328716   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4054870376287148   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.411962509155273\n",
      "Epoch: 24   Train loss: 0.4428436396240491   Top1 accuracy: 99.86842105263158   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.40994508599328716   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.585445165634155\n",
      "Epoch: 25   Train loss: 0.4477352187124609   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4209328848018981   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.61999773979187\n",
      "Epoch: 26   Train loss: 0.43874269506038976   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4072119862015484   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.606647491455078\n",
      "Epoch: 27   Train loss: 0.4378619437154971   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4058316999185852   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.7113094329834\n",
      "Epoch: 28   Train loss: 0.435447966669038   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41137268067451943   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.73899507522583\n",
      "Epoch: 29   Train loss: 0.4400942553030817   Top1 accuracy: 99.8391812865497   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.41047091686237624   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.77841067314148\n",
      "best epoch: 8, train top1 acc:99.927, top5 acc:100.000; val top1 acc:99.956, top5 acc:100.000, train loss:0.4530, val loss: 0.4164\n",
      "val sub [1]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.1808786434039735   Top1 accuracy: 68.40643274853801   Top5 accuracy: 81.21345029239767\n",
      "\tVal loss: 0.7651148881131445   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 27.369104623794556\n",
      "Epoch: 1   Train loss: 0.666852630195562   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4693107101303792   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.297257900238037\n",
      "Epoch: 2   Train loss: 0.5147488645294256   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41532346815393684   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.43982219696045\n",
      "Epoch: 3   Train loss: 0.4753805870375438   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3945863620753874   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.424874782562256\n",
      "Epoch: 4   Train loss: 0.4678449824190976   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.38700436778932984   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.549357175827026\n",
      "Epoch: 5   Train loss: 0.45489528200082613   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.38895562587425725   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.5993549823761\n",
      "Epoch: 6   Train loss: 0.45535062610754495   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3832078920296061   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.607756853103638\n",
      "Epoch: 7   Train loss: 0.4645169772948438   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3797086099957862   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.667741060256958\n",
      "Epoch: 8   Train loss: 0.442564416088556   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3849410394653242   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.674763441085815\n",
      "Epoch: 9   Train loss: 0.44845585437894564   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3702338222871747   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.682219743728638\n",
      "Epoch: 10   Train loss: 0.43779152605617255   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3702887784667879   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.723800659179688\n",
      "Epoch: 11   Train loss: 0.4453350268086495   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37727481675775426   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.5068678855896\n",
      "Epoch: 12   Train loss: 0.45435144503911334   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3827872776497177   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.28016185760498\n",
      "Epoch: 13   Train loss: 0.4333182284009387   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.38405590412909524   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.295246362686157\n",
      "Epoch: 14   Train loss: 0.4543050685298373   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37260402608336063   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.388460874557495\n",
      "Epoch: 15   Train loss: 0.4505701090334452   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3803320944483517   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.421440839767456\n",
      "Epoch: 16   Train loss: 0.4382779514580442   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3712163524843796   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.554381608963013\n",
      "Epoch: 17   Train loss: 0.4437427670634978   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3690056673615997   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.428365230560303\n",
      "Epoch: 18   Train loss: 0.4414781454885215   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37089886111125614   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.50291085243225\n",
      "Epoch: 19   Train loss: 0.45107473511444895   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37593845334666515   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.332836866378784\n",
      "Epoch: 20   Train loss: 0.43655949386588316   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3626451593393471   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.36138916015625\n",
      "Epoch: 21   Train loss: 0.44714779872991883   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3717376730072568   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.437227249145508\n",
      "Epoch: 22   Train loss: 0.4334618538966653   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37701764214805694   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.395885705947876\n",
      "Epoch: 23   Train loss: 0.4444522867251558   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.36560282154738555   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.361551523208618\n",
      "Epoch: 24   Train loss: 0.45239171795329153   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3754581366366113   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.31688165664673\n",
      "Epoch: 25   Train loss: 0.4436658451780241   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37017342648659535   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.29140615463257\n",
      "Epoch: 26   Train loss: 0.4369619829438583   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37110180525403275   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.267794609069824\n",
      "Epoch: 27   Train loss: 0.429755954888829   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3657875049706788   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.36411714553833\n",
      "Epoch: 28   Train loss: 0.44190082729559893   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3664100293004722   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.661733865737915\n",
      "Epoch: 29   Train loss: 0.4559688521930349   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3992921859897368   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.492896556854248\n",
      "best epoch: 3, train top1 acc:99.854, top5 acc:100.000; val top1 acc:100.000, top5 acc:100.000, train loss:0.4754, val loss: 0.3946\n",
      "val sub [2]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.455848290906315   Top1 accuracy: 63.30409356725146   Top5 accuracy: 75.5701754385965\n",
      "\tVal loss: 1.0495932579737657   Top1 accuracy: 99.12280701754386   Top5 accuracy: 99.97076023391813\n",
      "time consumed: 27.159446477890015\n",
      "Epoch: 1   Train loss: 0.7429639620390552   Top1 accuracy: 99.5906432748538   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.6359275762449231   Top1 accuracy: 99.64912280701755   Top5 accuracy: 100.0\n",
      "time consumed: 26.730092525482178\n",
      "Epoch: 2   Train loss: 0.5178372598530954   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5174195187830786   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.72172713279724\n",
      "Epoch: 3   Train loss: 0.46707700018645726   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4942886839833176   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.70080828666687\n",
      "Epoch: 4   Train loss: 0.4483679773514731   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4733720958581445   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 26.73300528526306\n",
      "Epoch: 5   Train loss: 0.4481137813183299   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4682051157742216   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.65533185005188\n",
      "Epoch: 6   Train loss: 0.44857803640658395   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4627454768844515   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.711260080337524\n",
      "Epoch: 7   Train loss: 0.4355199308248988   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45903718384385805   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.701913595199585\n",
      "Epoch: 8   Train loss: 0.434042270246305   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45754481982766537   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.644614458084106\n",
      "Epoch: 9   Train loss: 0.43308894118370367   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46286503996765405   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.7786808013916\n",
      "Epoch: 10   Train loss: 0.4343873375689077   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4596054320446929   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.801555633544922\n",
      "Epoch: 11   Train loss: 0.43754153119193184   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45630044965019   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.725555419921875\n",
      "Epoch: 12   Train loss: 0.43166290964299475   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45895708809819136   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.818150997161865\n",
      "Epoch: 13   Train loss: 0.43711392363609625   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46331803788218584   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 26.76264452934265\n",
      "Epoch: 14   Train loss: 0.43307522653836256   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45597915795811433   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.78990125656128\n",
      "Epoch: 15   Train loss: 0.43638164493424153   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47490155191449396   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 26.740254163742065\n",
      "Epoch: 16   Train loss: 0.43853546069030874   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4533083517300455   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.68689727783203\n",
      "Epoch: 17   Train loss: 0.4365130494735394   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4480368606528344   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.712110996246338\n",
      "Epoch: 18   Train loss: 0.43438830788721117   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4737991960773691   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "time consumed: 26.727900743484497\n",
      "Epoch: 19   Train loss: 0.4327617303321236   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4655909440670794   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.784188508987427\n",
      "Epoch: 20   Train loss: 0.4397310607614573   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44850470883804455   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.73897886276245\n",
      "Epoch: 21   Train loss: 0.4258858515330923   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4523410120902703   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.705819129943848\n",
      "Epoch: 22   Train loss: 0.43008081065981013   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45282179343770124   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.679428815841675\n",
      "Epoch: 23   Train loss: 0.43428967614271485   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.458683491101739   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 26.64522433280945\n",
      "Epoch: 24   Train loss: 0.43628744406309744   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46775483806230866   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.701208114624023\n",
      "Epoch: 25   Train loss: 0.43839051753108266   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46273719166454513   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.644739866256714\n",
      "Epoch: 26   Train loss: 0.4338117274973128   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45045795060737787   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.657588243484497\n",
      "Epoch: 27   Train loss: 0.538774543425493   Top1 accuracy: 97.69005847953217   Top5 accuracy: 99.22514619883042\n",
      "\tVal loss: 0.5326613747237021   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.67245078086853\n",
      "Epoch: 28   Train loss: 0.44806136478457537   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.456447945875034   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 26.692853689193726\n",
      "Epoch: 29   Train loss: 0.42301399160546865   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4560836048154106   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.644699096679688\n",
      "best epoch: 12, train top1 acc:99.825, top5 acc:100.000; val top1 acc:99.839, top5 acc:100.000, train loss:0.4317, val loss: 0.4590\n",
      "val sub [3]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.729428029548355   Top1 accuracy: 57.30994152046784   Top5 accuracy: 69.69298245614036\n",
      "\tVal loss: 1.1230549669405172   Top1 accuracy: 99.28362573099415   Top5 accuracy: 99.97076023391813\n",
      "time consumed: 27.27055048942566\n",
      "Epoch: 1   Train loss: 0.7237031986141762   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.6068621427692168   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "time consumed: 26.207099437713623\n",
      "Epoch: 2   Train loss: 0.5097353132496103   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5201861856625094   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.19741129875183\n",
      "Epoch: 3   Train loss: 0.45435573169362475   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.501575606782534   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.69131851196289\n",
      "Epoch: 4   Train loss: 0.45244547411015157   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48621484654688696   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.47518277168274\n",
      "Epoch: 5   Train loss: 0.44253645541026576   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4813200651902204   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.532700777053833\n",
      "Epoch: 6   Train loss: 0.4288295739226871   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47460412038000005   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.510989904403687\n",
      "Epoch: 7   Train loss: 0.4382050472219088   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4764617859271535   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.476585388183594\n",
      "Epoch: 8   Train loss: 0.44190638028738793   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48736932455447685   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.395856142044067\n",
      "Epoch: 9   Train loss: 0.43339127084316564   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4690434152794163   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.38285732269287\n",
      "Epoch: 10   Train loss: 0.4304808333777545   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4659268357600385   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.40240979194641\n",
      "Epoch: 11   Train loss: 0.4383010378009395   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47745429998949956   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.406007766723633\n",
      "Epoch: 12   Train loss: 0.4276727432744545   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4789817209480799   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.400573015213013\n",
      "Epoch: 13   Train loss: 0.4252483025628921   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4638106533658435   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.42808747291565\n",
      "Epoch: 14   Train loss: 0.4389300193005835   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48504625426398384   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.42760992050171\n",
      "Epoch: 15   Train loss: 0.4371286809270145   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4695350808358332   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.384114742279053\n",
      "Epoch: 16   Train loss: 0.4287269558997182   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47532073412722314   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.405797481536865\n",
      "Epoch: 17   Train loss: 0.4304721902685556   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4664566562189693   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.33842921257019\n",
      "Epoch: 18   Train loss: 0.4475536883225915   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4745434822394834   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 26.48530673980713\n",
      "Epoch: 19   Train loss: 0.4329199085110112   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47849480555071466   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.415072441101074\n",
      "Epoch: 20   Train loss: 0.42458153581410124   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47181931364606   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.334988594055176\n",
      "Epoch: 21   Train loss: 0.4301731944607015   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4651233282005578   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.35723090171814\n",
      "Epoch: 22   Train loss: 0.42924436395279847   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4662204696769603   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.285539865493774\n",
      "Epoch: 23   Train loss: 0.43217334159982135   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5281575916454806   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.295610427856445\n",
      "Epoch: 24   Train loss: 0.4358582520171216   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46128990880230014   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.25495409965515\n",
      "Epoch: 25   Train loss: 0.4308690504546751   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47447532432818273   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.225539207458496\n",
      "Epoch: 26   Train loss: 0.4323480483907008   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.464130031957961   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.256580114364624\n",
      "Epoch: 27   Train loss: 0.43258105462406116   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4632201484072278   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.24817395210266\n",
      "Epoch: 28   Train loss: 0.4323098557560067   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4666795338454999   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.209553718566895\n",
      "Epoch: 29   Train loss: 0.4489963625432455   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46475926764875825   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.33004856109619\n",
      "best epoch: 9, train top1 acc:99.795, top5 acc:100.000; val top1 acc:99.927, top5 acc:100.000, train loss:0.4334, val loss: 0.4690\n",
      "val sub [4]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.3146907028399015   Top1 accuracy: 67.6608187134503   Top5 accuracy: 79.95614035087719\n",
      "\tVal loss: 0.8957805964681838   Top1 accuracy: 99.53216374269006   Top5 accuracy: 99.97076023391813\n",
      "time consumed: 27.041900873184204\n",
      "Epoch: 1   Train loss: 0.648898683967646   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5469931848565041   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.784040212631226\n",
      "Epoch: 2   Train loss: 0.4946521487500932   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.487369192796841   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.74733877182007\n",
      "Epoch: 3   Train loss: 0.4579725824950034   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4666850380381646   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.77176833152771\n",
      "Epoch: 4   Train loss: 0.44682456343843224   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4576392698357677   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.79365611076355\n",
      "Epoch: 5   Train loss: 0.4438543703995253   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45768843303646956   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.699791193008423\n",
      "Epoch: 6   Train loss: 0.44308126574022727   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47364412378846554   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.793588638305664\n",
      "Epoch: 7   Train loss: 0.45228570542837443   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45341921758930587   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.818689107894897\n",
      "Epoch: 8   Train loss: 0.43571074829812634   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4458765148767951   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.80696415901184\n",
      "Epoch: 9   Train loss: 0.44538658674348863   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4758285353755393   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.78316378593445\n",
      "Epoch: 10   Train loss: 0.4409961009408995   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4593316900451281   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.87544083595276\n",
      "Epoch: 11   Train loss: 0.43490133979167156   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4415945422928236   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.773407697677612\n",
      "Epoch: 12   Train loss: 0.4388361512220394   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46602528119644926   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.77849054336548\n",
      "Epoch: 13   Train loss: 0.44114873100791063   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45629258828553537   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.781858444213867\n",
      "Epoch: 14   Train loss: 0.4419460072677735   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44595153812776533   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.83174204826355\n",
      "Epoch: 15   Train loss: 0.4312671174605687   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4425427432645831   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.790982007980347\n",
      "Epoch: 16   Train loss: 0.44626506927766296   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4505866797346818   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.823519468307495\n",
      "Epoch: 17   Train loss: 0.42939983465169607   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4448951834823653   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.817063570022583\n",
      "Epoch: 18   Train loss: 0.43446767521880525   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44590609551173205   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.761494874954224\n",
      "Epoch: 19   Train loss: 0.43368479722773123   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4389875437083997   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.7774076461792\n",
      "Epoch: 20   Train loss: 0.4436005156116876   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45029779205545345   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.783079385757446\n",
      "Epoch: 21   Train loss: 0.431260477991132   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44843919949921945   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.772399425506592\n",
      "Epoch: 22   Train loss: 0.43536332458780524   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.437472807385071   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.76680064201355\n",
      "Epoch: 23   Train loss: 0.43481622662460595   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.458451902831507   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.759729146957397\n",
      "Epoch: 24   Train loss: 0.4353110095736576   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44430973951579533   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.826616525650024\n",
      "Epoch: 25   Train loss: 0.43480130698945785   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4454927562970167   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.776045083999634\n",
      "Epoch: 26   Train loss: 0.4349586085269326   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4513286352157593   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.752604246139526\n",
      "Epoch: 27   Train loss: 0.44593522031056254   Top1 accuracy: 99.70760233918129   Top5 accuracy: 99.92690058479532\n",
      "\tVal loss: 0.4455555602472428   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.748072385787964\n",
      "Epoch: 28   Train loss: 0.4299775988560671   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4416152081991497   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.728351831436157\n",
      "Epoch: 29   Train loss: 0.43474493711663964   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4426025429315734   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.773102045059204\n",
      "best epoch: 6, train top1 acc:99.942, top5 acc:100.000; val top1 acc:99.942, top5 acc:100.000, train loss:0.4431, val loss: 0.4736\n",
      "val sub [5]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.446171210174672   Top1 accuracy: 59.92690058479532   Top5 accuracy: 71.95906432748538\n",
      "\tVal loss: 1.0341152684730397   Top1 accuracy: 99.35672514619883   Top5 accuracy: 99.94152046783626\n",
      "time consumed: 27.55952525138855\n",
      "Epoch: 1   Train loss: 0.7084424283072265   Top1 accuracy: 99.69298245614036   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.6305002903032024   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.419580936431885\n",
      "Epoch: 2   Train loss: 0.5181596653851849   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5627419763838338   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.39653491973877\n",
      "Epoch: 3   Train loss: 0.47382605180405735   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5249998348149639   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.55746078491211\n",
      "Epoch: 4   Train loss: 0.44873433407635716   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5161625676684909   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.543699264526367\n",
      "Epoch: 5   Train loss: 0.4408099610380262   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5072861338219448   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.612678050994873\n",
      "Epoch: 6   Train loss: 0.44022737704870996   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5081139790732958   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.64714217185974\n",
      "Epoch: 7   Train loss: 0.4387702023425297   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5033366861399154   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.61177706718445\n",
      "Epoch: 8   Train loss: 0.44063905282327304   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49693475149528327   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.6483371257782\n",
      "Epoch: 9   Train loss: 0.43742686876079495   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4979917879341639   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.553362607955933\n",
      "Epoch: 10   Train loss: 0.4352308197153939   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49302486578623456   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.593414545059204\n",
      "Epoch: 11   Train loss: 0.4331031892209025   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49606834587297943   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.6106915473938\n",
      "Epoch: 12   Train loss: 0.43946896214582765   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5208433629476537   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.606107234954834\n",
      "Epoch: 13   Train loss: 0.4248768889416031   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49692567154677986   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.547834873199463\n",
      "Epoch: 14   Train loss: 0.43008586712050856   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5058295768603944   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 26.504074096679688\n",
      "Epoch: 15   Train loss: 0.4294715857470942   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49323469696686284   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.67048406600952\n",
      "Epoch: 16   Train loss: 0.42171222076081394   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4957873361152515   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.64126706123352\n",
      "Epoch: 17   Train loss: 0.42021131707213777   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5238254619272131   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.66006898880005\n",
      "Epoch: 18   Train loss: 0.4421160673363167   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4940988973915926   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.607062816619873\n",
      "Epoch: 19   Train loss: 0.4303029047989706   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4984929943293856   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.36687994003296\n",
      "Epoch: 20   Train loss: 0.4270510731036203   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4885138926798837   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.387497901916504\n",
      "Epoch: 21   Train loss: 0.44160013066397774   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.509349430862226   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 26.39865207672119\n",
      "Epoch: 22   Train loss: 0.43391516874408165   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4873952666918437   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.414591550827026\n",
      "Epoch: 23   Train loss: 0.43326518645412043   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49007298827868456   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.44605040550232\n",
      "Epoch: 24   Train loss: 0.42576756280416633   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4904697192342658   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.4337637424469\n",
      "Epoch: 25   Train loss: 0.425027021364859   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5026799804634519   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 26.432824850082397\n",
      "Epoch: 26   Train loss: 0.42501330253673575   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4935318242039597   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.361208200454712\n",
      "Epoch: 27   Train loss: 0.4169294130906724   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4921657050910749   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.471044063568115\n",
      "Epoch: 28   Train loss: 0.42678362131118774   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49305692942518936   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.445663928985596\n",
      "Epoch: 29   Train loss: 0.42514672369984857   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.494925342108074   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.400833129882812\n",
      "best epoch: 3, train top1 acc:99.898, top5 acc:100.000; val top1 acc:99.912, top5 acc:100.000, train loss:0.4738, val loss: 0.5250\n",
      "val sub [6]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.548598007151955   Top1 accuracy: 59.751461988304094   Top5 accuracy: 71.09649122807018\n",
      "\tVal loss: 0.9856387788092184   Top1 accuracy: 99.02046783625731   Top5 accuracy: 100.0\n",
      "time consumed: 27.041155576705933\n",
      "Epoch: 1   Train loss: 0.7043484675953959   Top1 accuracy: 99.51754385964912   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.603645493238293   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.185353994369507\n",
      "Epoch: 2   Train loss: 0.5115033531049539   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5045633031959422   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.233442306518555\n",
      "Epoch: 3   Train loss: 0.4704842203193241   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49461379943535344   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.3486270904541\n",
      "Epoch: 4   Train loss: 0.4508080515596602   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4888734076803888   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.322465181350708\n",
      "Epoch: 5   Train loss: 0.44082084550843603   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47534765869553325   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.355277061462402\n",
      "Epoch: 6   Train loss: 0.44589309734210636   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.482496379847415   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.38782811164856\n",
      "Epoch: 7   Train loss: 0.4375721545595872   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46732083346411496   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.35687494277954\n",
      "Epoch: 8   Train loss: 0.43923705467703744   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46029630102957897   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.472480535507202\n",
      "Epoch: 9   Train loss: 0.42636950261760176   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4722372793663315   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.39698624610901\n",
      "Epoch: 10   Train loss: 0.4416964612683358   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4747494961086072   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.460124731063843\n",
      "Epoch: 11   Train loss: 0.43148734520750437   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4617727720423749   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.564157485961914\n",
      "Epoch: 12   Train loss: 0.43690583231853464   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4591491647631104   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.729027271270752\n",
      "Epoch: 13   Train loss: 0.4259639361448455   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45319621866209464   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.68152689933777\n",
      "Epoch: 14   Train loss: 0.442299904094802   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4651246278258095   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.700793027877808\n",
      "Epoch: 15   Train loss: 0.4376955863676573   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46972785105830744   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.608123540878296\n",
      "Epoch: 16   Train loss: 0.4353684148593256   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4647000077349401   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.57764434814453\n",
      "Epoch: 17   Train loss: 0.4292177523960147   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46141342618312053   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.60068941116333\n",
      "Epoch: 18   Train loss: 0.432514639800055   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4738921014189023   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.58904790878296\n",
      "Epoch: 19   Train loss: 0.42428895499971175   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46341208390325134   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.33747625350952\n",
      "Epoch: 20   Train loss: 0.43556475055496596   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46414420810359264   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.156435251235962\n",
      "Epoch: 21   Train loss: 0.4274036166263603   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4615058655801572   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.46839690208435\n",
      "Epoch: 22   Train loss: 0.4322051276937563   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46766313927912573   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.627931118011475\n",
      "Epoch: 23   Train loss: 0.4259226409315366   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4654534337116264   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.65471863746643\n",
      "Epoch: 24   Train loss: 0.44077453618509727   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46378162485814234   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.496896505355835\n",
      "Epoch: 25   Train loss: 0.43240685368839066   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46057940888823123   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.540367603302002\n",
      "Epoch: 26   Train loss: 0.43092055967328147   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45438974102338153   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.504589796066284\n",
      "Epoch: 27   Train loss: 0.4418637467580929   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4503109002845329   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.531460285186768\n",
      "Epoch: 28   Train loss: 0.4373519409295411   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4691697627480267   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 27.81296181678772\n",
      "Epoch: 29   Train loss: 0.43183342659333995   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4564791957885898   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.36217474937439\n",
      "best epoch: 10, train top1 acc:99.854, top5 acc:100.000; val top1 acc:99.956, top5 acc:100.000, train loss:0.4417, val loss: 0.4747\n",
      "val sub [7]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.6575620442803145   Top1 accuracy: 58.333333333333336   Top5 accuracy: 71.6374269005848\n",
      "\tVal loss: 1.1075805707981712   Top1 accuracy: 99.45906432748538   Top5 accuracy: 99.95614035087719\n",
      "time consumed: 28.164331197738647\n",
      "Epoch: 1   Train loss: 0.7413565776152917   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5629971020402964   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.303893327713013\n",
      "Epoch: 2   Train loss: 0.51292392907784   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47862387139197676   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.164835214614868\n",
      "Epoch: 3   Train loss: 0.4694419328057975   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44831580707901403   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.23432469367981\n",
      "Epoch: 4   Train loss: 0.4473089755278582   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4416209611802073   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.261163234710693\n",
      "Epoch: 5   Train loss: 0.4436752825801136   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4329375283062807   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.112224102020264\n",
      "Epoch: 6   Train loss: 0.4405020034452628   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4363658138011631   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.240519046783447\n",
      "Epoch: 7   Train loss: 0.44584457175424924   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4415964698582365   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.14898371696472\n",
      "Epoch: 8   Train loss: 0.4591965115035487   Top1 accuracy: 99.76608187134502   Top5 accuracy: 99.94152046783626\n",
      "\tVal loss: 0.4330255819691552   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.258265733718872\n",
      "Epoch: 9   Train loss: 0.4385119473550752   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42712330365041545   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.03967261314392\n",
      "Epoch: 10   Train loss: 0.43089211475082306   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.437094792810797   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.10976529121399\n",
      "Epoch: 11   Train loss: 0.43840939329381573   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4299667925513976   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.176247596740723\n",
      "Epoch: 12   Train loss: 0.4303374065641771   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4242292031732916   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.08310341835022\n",
      "Epoch: 13   Train loss: 0.4397514750037277   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43296020752505254   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.19377088546753\n",
      "Epoch: 14   Train loss: 0.4309315082796833   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4268926161597347   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.310871362686157\n",
      "Epoch: 15   Train loss: 0.4437156189777698   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4427589575449626   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.27483606338501\n",
      "Epoch: 16   Train loss: 0.4371110793442754   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42477022590692975   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.367430925369263\n",
      "Epoch: 17   Train loss: 0.43598591958918764   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42302412613790635   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.316751956939697\n",
      "Epoch: 18   Train loss: 0.4403328200181325   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43328480265642466   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.300838708877563\n",
      "Epoch: 19   Train loss: 0.4396952876919194   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4211672134043878   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.23071026802063\n",
      "Epoch: 20   Train loss: 0.43424680585052533   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4302074760198593   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.31744956970215\n",
      "Epoch: 21   Train loss: 0.4587881649621049   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44145477001081435   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.40097403526306\n",
      "Epoch: 22   Train loss: 0.44309530280835446   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.425901154328508   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.449187755584717\n",
      "Epoch: 23   Train loss: 0.4352626228890224   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4323717082975901   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.344717502593994\n",
      "Epoch: 24   Train loss: 0.4336305198787946   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42756604547040505   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.321675300598145\n",
      "Epoch: 25   Train loss: 0.4380836702055401   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4229453406487292   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.36666202545166\n",
      "Epoch: 26   Train loss: 0.4419677650545076   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41915791459948   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.439788103103638\n",
      "Epoch: 27   Train loss: 0.43231496955567633   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4210532894957135   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.520771265029907\n",
      "Epoch: 28   Train loss: 0.42778088727541136   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42552355960098626   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.49112057685852\n",
      "Epoch: 29   Train loss: 0.4353046846842905   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4177700326456661   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.46361207962036\n",
      "best epoch: 3, train top1 acc:99.927, top5 acc:100.000; val top1 acc:99.942, top5 acc:100.000, train loss:0.4694, val loss: 0.4483\n",
      "val sub [8]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.264268096078906   Top1 accuracy: 69.26900584795321   Top5 accuracy: 78.62573099415205\n",
      "\tVal loss: 0.8977019591638219   Top1 accuracy: 99.66374269005848   Top5 accuracy: 99.97076023391813\n",
      "time consumed: 27.259775161743164\n",
      "Epoch: 1   Train loss: 0.6391023503758057   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5762654511552108   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.791797399520874\n",
      "Epoch: 2   Train loss: 0.4771344881308706   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.511557561437986   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 26.793811082839966\n",
      "Epoch: 3   Train loss: 0.4635246131155226   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5027472477907325   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.76615047454834\n",
      "Epoch: 4   Train loss: 0.4486565183826357   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5065136060380099   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.756736516952515\n",
      "Epoch: 5   Train loss: 0.43734440878469344   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49949938947694345   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.724470376968384\n",
      "Epoch: 6   Train loss: 0.44228418302117734   Top1 accuracy: 99.80994152046783   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.4892460186230509   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 26.79237937927246\n",
      "Epoch: 7   Train loss: 0.4342872425478104   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49299292919928567   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.887256383895874\n",
      "Epoch: 8   Train loss: 0.4408355541745124   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48519893103872824   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.76511001586914\n",
      "Epoch: 9   Train loss: 0.42604365012450524   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4892186320316025   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.689291954040527\n",
      "Epoch: 10   Train loss: 0.4345457133842491   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5018894086804306   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "time consumed: 26.671189308166504\n",
      "Epoch: 11   Train loss: 0.43496019728699625   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5002303482496251   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.812632083892822\n",
      "Epoch: 12   Train loss: 0.4477502381243901   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.496091039557206   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.78904366493225\n",
      "Epoch: 13   Train loss: 0.4286108157265256   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49436683368961715   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.790338277816772\n",
      "Epoch: 14   Train loss: 0.43373313380612266   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48703264963557147   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.74626064300537\n",
      "Epoch: 15   Train loss: 0.4326024301219405   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48561002549372223   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 26.801076412200928\n",
      "Epoch: 16   Train loss: 0.42665125464486797   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4959325340756199   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.826964855194092\n",
      "Epoch: 17   Train loss: 0.43057453780494936   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4943290060026604   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.831974506378174\n",
      "Epoch: 18   Train loss: 0.43772735477190966   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4868901363241742   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.817758798599243\n",
      "Epoch: 19   Train loss: 0.43695792982801357   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4908954968229372   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 26.85115933418274\n",
      "Epoch: 20   Train loss: 0.426214832834333   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.481569683865497   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.76337742805481\n",
      "Epoch: 21   Train loss: 0.4491047582082581   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5056846310869295   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.825400590896606\n",
      "Epoch: 22   Train loss: 0.42789523503933735   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48696047189640024   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.8455810546875\n",
      "Epoch: 23   Train loss: 0.4257217868726853   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4802976271562409   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.77091646194458\n",
      "Epoch: 24   Train loss: 0.4337093903307329   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48805679790457784   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 26.758118629455566\n",
      "Epoch: 25   Train loss: 0.4321701643411179   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48485166078422504   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 26.819769382476807\n",
      "Epoch: 26   Train loss: 0.42148176794163666   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4803593747797068   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.828875303268433\n",
      "Epoch: 27   Train loss: 0.43070103707369306   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48858232996617146   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 26.84292721748352\n",
      "Epoch: 28   Train loss: 0.485782135648337   Top1 accuracy: 99.07894736842105   Top5 accuracy: 99.78070175438596\n",
      "\tVal loss: 0.517560542152639   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 26.781198024749756\n",
      "Epoch: 29   Train loss: 0.41834052020346213   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47529958946663037   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 26.807666063308716\n",
      "best epoch: 6, train top1 acc:99.810, top5 acc:99.985; val top1 acc:99.912, top5 acc:100.000, train loss:0.4423, val loss: 0.4892\n",
      "val sub [9]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.8505692823588498   Top1 accuracy: 53.40643274853801   Top5 accuracy: 65.83333333333333\n",
      "\tVal loss: 1.0837533372884605   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "time consumed: 27.593648195266724\n",
      "Epoch: 1   Train loss: 0.8137970486579583   Top1 accuracy: 99.67836257309942   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.551231415822492   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.718128204345703\n",
      "Epoch: 2   Train loss: 0.5613103118556285   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4267812709362186   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.787687063217163\n",
      "Epoch: 3   Train loss: 0.48734386901409305   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.38214502313680815   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.308753967285156\n",
      "Epoch: 4   Train loss: 0.46635020406622635   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37244297171893875   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.18084955215454\n",
      "Epoch: 5   Train loss: 0.45457006494204205   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3663151132607321   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.20085334777832\n",
      "Epoch: 6   Train loss: 0.4543062742167746   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.37710861147147173   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.19083857536316\n",
      "Epoch: 7   Train loss: 0.45251876734502133   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.36007846351604017   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.140251398086548\n",
      "Epoch: 8   Train loss: 0.4524117542637719   Top1 accuracy: 99.8391812865497   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.3600259443298418   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.15281581878662\n",
      "Epoch: 9   Train loss: 0.44846190425039034   Top1 accuracy: 99.85380116959064   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.3625562838469332   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.16683554649353\n",
      "Epoch: 10   Train loss: 0.4499735000015002   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3592862312556707   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.19436740875244\n",
      "Epoch: 11   Train loss: 0.4458812682600746   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3673050074200881   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.204742670059204\n",
      "Epoch: 12   Train loss: 0.4459249744115517   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35386717476342855   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.221567630767822\n",
      "Epoch: 13   Train loss: 0.4465771544920771   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.36672217760518283   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.184951305389404\n",
      "Epoch: 14   Train loss: 0.4501465362937827   Top1 accuracy: 99.91228070175438   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.3511615873080248   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.188796281814575\n",
      "Epoch: 15   Train loss: 0.4489236115886454   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3529646130856018   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.160417556762695\n",
      "Epoch: 16   Train loss: 0.44306265070424444   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3551014687059916   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.16645312309265\n",
      "Epoch: 17   Train loss: 0.449070278838364   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3622915855450937   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.136136293411255\n",
      "Epoch: 18   Train loss: 0.4434543107336725   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35137699727426497   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.203902006149292\n",
      "Epoch: 19   Train loss: 0.45961389163432764   Top1 accuracy: 99.72222222222223   Top5 accuracy: 99.95614035087719\n",
      "\tVal loss: 0.39536650199987733   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.214905738830566\n",
      "Epoch: 20   Train loss: 0.451050976737898   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.351207040293872   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.161751747131348\n",
      "Epoch: 21   Train loss: 0.43726028249277704   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35408722073362586   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.20960235595703\n",
      "Epoch: 22   Train loss: 0.4321128701605992   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3510316084002891   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.218297004699707\n",
      "Epoch: 23   Train loss: 0.43365097873740727   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35150658857752703   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.163889408111572\n",
      "Epoch: 24   Train loss: 0.4488362229009818   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35675574943684696   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.11689305305481\n",
      "Epoch: 25   Train loss: 0.4422163992074498   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34497918293141483   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.156428813934326\n",
      "Epoch: 26   Train loss: 0.43619966838094926   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3491040025538171   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.221031188964844\n",
      "Epoch: 27   Train loss: 0.43584488462983517   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.353870304530127   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.171510457992554\n",
      "Epoch: 28   Train loss: 0.45526328142623457   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34938740991709527   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.22349524497986\n",
      "Epoch: 29   Train loss: 0.45806507469966395   Top1 accuracy: 99.64912280701755   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.36493339995194596   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.17138981819153\n",
      "best epoch: 16, train top1 acc:99.854, top5 acc:100.000; val top1 acc:99.985, top5 acc:100.000, train loss:0.4431, val loss: 0.3551\n",
      "val sub [10]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.4805512975531014   Top1 accuracy: 61.12573099415204   Top5 accuracy: 71.72514619883042\n",
      "\tVal loss: 0.7673431136454755   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.84131669998169\n",
      "Epoch: 1   Train loss: 0.7114718563375417   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4498556399205972   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.768994092941284\n",
      "Epoch: 2   Train loss: 0.5147183513083653   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.38782554010898745   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.556983947753906\n",
      "Epoch: 3   Train loss: 0.478734676949462   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.36137016622992285   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.72888469696045\n",
      "Epoch: 4   Train loss: 0.4598219487053609   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35214173915790536   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.79221534729004\n",
      "Epoch: 5   Train loss: 0.46155507958423325   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3523961833694525   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.850029230117798\n",
      "Epoch: 6   Train loss: 0.4553893637238887   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34335166730030237   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.811688899993896\n",
      "Epoch: 7   Train loss: 0.4534403894379822   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3377223950729035   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.72732400894165\n",
      "Epoch: 8   Train loss: 0.46008749314916064   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34704355102533485   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.79353141784668\n",
      "Epoch: 9   Train loss: 0.45421393668791005   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3422052179686507   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.768064737319946\n",
      "Epoch: 10   Train loss: 0.44638795087560573   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3479324754392892   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.806337594985962\n",
      "Epoch: 11   Train loss: 0.452737976845942   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33919764898325266   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.786317348480225\n",
      "Epoch: 12   Train loss: 0.4568835081238496   Top1 accuracy: 99.7953216374269   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.38005590726409044   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.100162267684937\n",
      "Epoch: 13   Train loss: 0.45385316179858315   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33645850332856875   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.044723987579346\n",
      "Epoch: 14   Train loss: 0.44858921219033804   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34317866333743985   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.89475417137146\n",
      "Epoch: 15   Train loss: 0.4486160449988661   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34062436179459443   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.971440076828003\n",
      "Epoch: 16   Train loss: 0.4569874015467906   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.334259314930927   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.994415760040283\n",
      "Epoch: 17   Train loss: 0.453633200791147   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3660795208480623   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.03230857849121\n",
      "Epoch: 18   Train loss: 0.4450459014951137   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3343999289978317   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.991660594940186\n",
      "Epoch: 19   Train loss: 0.4515236909800803   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3435596691237556   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.99752902984619\n",
      "Epoch: 20   Train loss: 0.43844578410798346   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33522281756526545   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 24.994688987731934\n",
      "Epoch: 21   Train loss: 0.457585611451439   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3485443498830349   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.93309712409973\n",
      "Epoch: 22   Train loss: 0.44535379233764627   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33963356110436177   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.89994764328003\n",
      "Epoch: 23   Train loss: 0.44095200160790604   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3465311664064028   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.909762144088745\n",
      "Epoch: 24   Train loss: 0.4461729892513208   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.343407076614642   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 24.91109013557434\n",
      "Epoch: 25   Train loss: 0.4446828643306654   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3390420728433899   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.871843099594116\n",
      "Epoch: 26   Train loss: 0.44201746260562136   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3367062094267349   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 24.914197206497192\n",
      "Epoch: 27   Train loss: 0.4470144625295672   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33840800699783347   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.891936540603638\n",
      "Epoch: 28   Train loss: 0.4744049162544005   Top1 accuracy: 99.29824561403508   Top5 accuracy: 99.80994152046783\n",
      "\tVal loss: 0.4446475094521952   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.879011869430542\n",
      "Epoch: 29   Train loss: 0.45515734985557915   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3442024696640104   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 24.820643424987793\n",
      "best epoch: 20, train top1 acc:99.868, top5 acc:100.000; val top1 acc:100.000, top5 acc:100.000, train loss:0.4384, val loss: 0.3352\n",
      "val sub [11]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.563371761849052   Top1 accuracy: 57.909356725146196   Top5 accuracy: 71.25730994152046\n",
      "\tVal loss: 1.1253385728562784   Top1 accuracy: 98.0701754385965   Top5 accuracy: 99.92690058479532\n",
      "time consumed: 26.299344539642334\n",
      "Epoch: 1   Train loss: 0.7160798316461998   Top1 accuracy: 99.44444444444444   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.7075824810747515   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "time consumed: 24.949649333953857\n",
      "Epoch: 2   Train loss: 0.5134647630634364   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.6122610117608344   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 24.931220531463623\n",
      "Epoch: 3   Train loss: 0.4598921244604546   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5748381529286591   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.919363260269165\n",
      "Epoch: 4   Train loss: 0.4421397081592627   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5663170708201782   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.932471752166748\n",
      "Epoch: 5   Train loss: 0.43244753098278715   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5718368758932192   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "time consumed: 24.94958472251892\n",
      "Epoch: 6   Train loss: 0.4284196242428662   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5645880071740401   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.982894897460938\n",
      "Epoch: 7   Train loss: 0.4315978138767488   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5553215480687326   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 25.023715257644653\n",
      "Epoch: 8   Train loss: 0.44512693392254454   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5952858722697921   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 25.01636576652527\n",
      "Epoch: 9   Train loss: 0.4361625054949208   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5533025393709105   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "time consumed: 25.016436338424683\n",
      "Epoch: 10   Train loss: 0.41438851771298907   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.554566952045898   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "time consumed: 24.900208711624146\n",
      "Epoch: 11   Train loss: 0.4344698323143853   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5543470551744539   Top1 accuracy: 99.64912280701755   Top5 accuracy: 100.0\n",
      "time consumed: 24.963931560516357\n",
      "Epoch: 12   Train loss: 0.420007541949986   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5444265649332638   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.96138310432434\n",
      "Epoch: 13   Train loss: 0.41961076829517097   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5473617203751503   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "time consumed: 24.961790800094604\n",
      "Epoch: 14   Train loss: 0.4168837511400033   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5480753160708132   Top1 accuracy: 99.69298245614036   Top5 accuracy: 100.0\n",
      "time consumed: 24.904824018478394\n",
      "Epoch: 15   Train loss: 0.42103399946327097   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5521147366155658   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.957143306732178\n",
      "Epoch: 16   Train loss: 0.43788297805521226   Top1 accuracy: 99.78070175438596   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.5722332873888183   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 24.918322801589966\n",
      "Epoch: 17   Train loss: 0.4256451953398554   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5513624399029023   Top1 accuracy: 99.69298245614036   Top5 accuracy: 100.0\n",
      "time consumed: 24.881436586380005\n",
      "Epoch: 18   Train loss: 0.42490441905476195   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.550246174572504   Top1 accuracy: 99.69298245614036   Top5 accuracy: 100.0\n",
      "time consumed: 24.756950855255127\n",
      "Epoch: 19   Train loss: 0.4185331393229334   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5519258838299422   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "time consumed: 24.763283252716064\n",
      "Epoch: 20   Train loss: 0.4263349044741246   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5517113761246553   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "time consumed: 24.820293426513672\n",
      "Epoch: 21   Train loss: 0.422140689098347   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5444459779220715   Top1 accuracy: 99.67836257309942   Top5 accuracy: 100.0\n",
      "time consumed: 24.68464732170105\n",
      "Epoch: 22   Train loss: 0.42215497068494384   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5710857984615348   Top1 accuracy: 99.67836257309942   Top5 accuracy: 100.0\n",
      "time consumed: 24.700986862182617\n",
      "Epoch: 23   Train loss: 0.43165540616763265   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5460221387489498   Top1 accuracy: 99.67836257309942   Top5 accuracy: 100.0\n",
      "time consumed: 24.727416038513184\n",
      "Epoch: 24   Train loss: 0.4179953047406604   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5564571688746849   Top1 accuracy: 99.64912280701755   Top5 accuracy: 100.0\n",
      "time consumed: 24.587456226348877\n",
      "Epoch: 25   Train loss: 0.42771635792757334   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.55474788438507   Top1 accuracy: 99.61988304093568   Top5 accuracy: 100.0\n",
      "time consumed: 24.656620264053345\n",
      "Epoch: 26   Train loss: 0.418571087787723   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5448150836933426   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.671213626861572\n",
      "Epoch: 27   Train loss: 0.41863137047890336   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5490215101785827   Top1 accuracy: 99.66374269005848   Top5 accuracy: 100.0\n",
      "time consumed: 24.71511149406433\n",
      "Epoch: 28   Train loss: 0.43033026786226974   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5515382112118236   Top1 accuracy: 99.72222222222223   Top5 accuracy: 100.0\n",
      "time consumed: 24.72305703163147\n",
      "Epoch: 29   Train loss: 0.43178444909073455   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5554362132883909   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "time consumed: 24.744232654571533\n",
      "best epoch: 2, train top1 acc:99.854, top5 acc:100.000; val top1 acc:99.825, top5 acc:100.000, train loss:0.5135, val loss: 0.6123\n",
      "val sub [12]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.242570194236019   Top1 accuracy: 72.67543859649123   Top5 accuracy: 81.71052631578948\n",
      "\tVal loss: 0.9836297467438101   Top1 accuracy: 99.29824561403508   Top5 accuracy: 99.98538011695906\n",
      "time consumed: 25.69474744796753\n",
      "Epoch: 1   Train loss: 0.675235851117742   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5954052980183161   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "time consumed: 25.196025371551514\n",
      "Epoch: 2   Train loss: 0.5022035001488457   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5218635774843874   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "time consumed: 25.237313985824585\n",
      "Epoch: 3   Train loss: 0.4548857849940919   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.503941434691524   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 25.23808240890503\n",
      "Epoch: 4   Train loss: 0.4358567414227982   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4984301549997943   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 25.26173758506775\n",
      "Epoch: 5   Train loss: 0.438047126371261   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.489464603320897   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.237601041793823\n",
      "Epoch: 6   Train loss: 0.4457320835855272   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48451761509242813   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 25.261181354522705\n",
      "Epoch: 7   Train loss: 0.4363476216618778   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5066569700227146   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 25.26693320274353\n",
      "Epoch: 8   Train loss: 0.4303924862230033   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4846539241180085   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.242443799972534\n",
      "Epoch: 9   Train loss: 0.4313281153203451   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.478989287078032   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.26424527168274\n",
      "Epoch: 10   Train loss: 0.4284790273298297   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48813482334739283   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.279369831085205\n",
      "Epoch: 11   Train loss: 0.4388609050135863   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49093220387285913   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 25.301401615142822\n",
      "Epoch: 12   Train loss: 0.4376372429188232   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4796705864674864   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.318030834197998\n",
      "Epoch: 13   Train loss: 0.42713764492879835   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4789260798378995   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 25.25836706161499\n",
      "Epoch: 14   Train loss: 0.42234674601526984   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47902574194105046   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.251424074172974\n",
      "Epoch: 15   Train loss: 0.4372031669519101   Top1 accuracy: 99.82456140350877   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.4758699013475786   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.2456533908844\n",
      "Epoch: 16   Train loss: 0.42772780027654433   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4893784207558771   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "time consumed: 25.265339612960815\n",
      "Epoch: 17   Train loss: 0.43542192109495576   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47656738113241587   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.24963641166687\n",
      "Epoch: 18   Train loss: 0.4244874626920934   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47685156736457557   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.255136966705322\n",
      "Epoch: 19   Train loss: 0.4746405948498096   Top1 accuracy: 99.34210526315789   Top5 accuracy: 99.8391812865497\n",
      "\tVal loss: 0.4768556663167407   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.22291851043701\n",
      "Epoch: 20   Train loss: 0.4213415095854921   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4779553944953004   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.216585397720337\n",
      "Epoch: 21   Train loss: 0.42660975543379087   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4802792473146093   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 25.259373426437378\n",
      "Epoch: 22   Train loss: 0.43157917147839975   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48823124693151104   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.261812210083008\n",
      "Epoch: 23   Train loss: 0.4277452611260944   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4801379963319901   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.261022090911865\n",
      "Epoch: 24   Train loss: 0.4485019638872983   Top1 accuracy: 99.70760233918129   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.5577139666205958   Top1 accuracy: 99.66374269005848   Top5 accuracy: 100.0\n",
      "time consumed: 25.266443967819214\n",
      "Epoch: 25   Train loss: 0.4261426674692254   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47665968554758886   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 25.223559856414795\n",
      "Epoch: 26   Train loss: 0.430879345065669   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47724239414895486   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.286498308181763\n",
      "Epoch: 27   Train loss: 0.4185596260933848   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4811714551253626   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.256898880004883\n",
      "Epoch: 28   Train loss: 0.42525508982396265   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.480312317609787   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.27088236808777\n",
      "Epoch: 29   Train loss: 0.4312171780052241   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4955767553452163   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 25.221111297607422\n",
      "best epoch: 22, train top1 acc:99.912, top5 acc:100.000; val top1 acc:99.898, top5 acc:100.000, train loss:0.4316, val loss: 0.4882\n",
      "val sub [13]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.2085067507816336   Top1 accuracy: 69.86842105263158   Top5 accuracy: 81.12573099415205\n",
      "\tVal loss: 0.8781883434245461   Top1 accuracy: 99.67836257309942   Top5 accuracy: 100.0\n",
      "time consumed: 26.718759059906006\n",
      "Epoch: 1   Train loss: 0.6757364170244563   Top1 accuracy: 99.75146198830409   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5170783020599544   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.123541355133057\n",
      "Epoch: 2   Train loss: 0.4974987212328883   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4513757446704552   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.882033824920654\n",
      "Epoch: 3   Train loss: 0.4662623663394772   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43081644055439017   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.868606567382812\n",
      "Epoch: 4   Train loss: 0.4609209106505266   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4246680476860693   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.000075340270996\n",
      "Epoch: 5   Train loss: 0.44964675361301465   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4223628554776398   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.32088875770569\n",
      "Epoch: 6   Train loss: 0.4461597795026344   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43168090031160944   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 27.047539949417114\n",
      "Epoch: 7   Train loss: 0.4470702110849626   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4198099079362133   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 28.44355607032776\n",
      "Epoch: 8   Train loss: 0.43857749712746047   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42119575531510584   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 26.615219116210938\n",
      "Epoch: 9   Train loss: 0.436970923466292   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4229475038441998   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.41896414756775\n",
      "Epoch: 10   Train loss: 0.44381395618469394   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.416626162696303   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 27.28669238090515\n",
      "Epoch: 11   Train loss: 0.43645550319325854   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41073960553832917   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 27.367884635925293\n",
      "Epoch: 12   Train loss: 0.44320132953730246   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40958448599653635   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 26.657873392105103\n",
      "Epoch: 13   Train loss: 0.432251647201895   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4221054454993086   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.600450038909912\n",
      "Epoch: 14   Train loss: 0.4617799431608434   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4188367500465516   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.43996286392212\n",
      "Epoch: 15   Train loss: 0.4403605102969889   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4118950235390524   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.863370418548584\n",
      "Epoch: 16   Train loss: 0.4371746122314219   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4130322115811688   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.692819833755493\n",
      "Epoch: 17   Train loss: 0.4350003011916813   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.414509567949507   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.962212800979614\n",
      "Epoch: 18   Train loss: 0.43609169508978635   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40738817805435223   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 25.54313588142395\n",
      "Epoch: 19   Train loss: 0.4414239915316565   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.40653099851650104   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.068732023239136\n",
      "Epoch: 20   Train loss: 0.4377068282916532   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.408190871888434   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 26.088394165039062\n",
      "Epoch: 21   Train loss: 0.43667001926410964   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4135493709329973   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.93977379798889\n",
      "Epoch: 22   Train loss: 0.44675174738928586   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41566252638722023   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.54055380821228\n",
      "Epoch: 23   Train loss: 0.44056865660070677   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4133354075122298   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 26.86275863647461\n",
      "Epoch: 24   Train loss: 0.44287157415995126   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42096738674138723   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 27.26085662841797\n",
      "Epoch: 25   Train loss: 0.4317086345968191   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4151473622224484   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.704253911972046\n",
      "Epoch: 26   Train loss: 0.4353453974451935   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.410172699400556   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.379615306854248\n",
      "Epoch: 27   Train loss: 0.4405373035118594   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4169629861039725   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 26.15332317352295\n",
      "Epoch: 28   Train loss: 0.43956676055813393   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.41222311695765335   Top1 accuracy: 100.0   Top5 accuracy: 100.0\n",
      "time consumed: 25.54216241836548\n",
      "Epoch: 29   Train loss: 0.43133987373078775   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4168530772303977   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 26.889909505844116\n",
      "best epoch: 10, train top1 acc:99.912, top5 acc:100.000; val top1 acc:100.000, top5 acc:100.000, train loss:0.4438, val loss: 0.4166\n",
      "val sub [14]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.442434409208465   Top1 accuracy: 63.39181286549707   Top5 accuracy: 73.9766081871345\n",
      "\tVal loss: 1.0271552030803168   Top1 accuracy: 99.45906432748538   Top5 accuracy: 100.0\n",
      "time consumed: 27.18936252593994\n",
      "Epoch: 1   Train loss: 0.7022868096828461   Top1 accuracy: 99.66374269005848   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.6453499082933393   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 26.09044361114502\n",
      "Epoch: 2   Train loss: 0.508948968865021   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.55457489811189   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 27.020256519317627\n",
      "Epoch: 3   Train loss: 0.4688341940007015   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.532945030788232   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.712096452713013\n",
      "Epoch: 4   Train loss: 0.44638639618778786   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.516143147185532   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.644803047180176\n",
      "Epoch: 5   Train loss: 0.4343693138737428   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5248613636396084   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.6979398727417\n",
      "Epoch: 6   Train loss: 0.43927911725657726   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5212198621348331   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.7349750995636\n",
      "Epoch: 7   Train loss: 0.44710446719886265   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.518385255371618   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.76520848274231\n",
      "Epoch: 8   Train loss: 0.4453438496031956   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5080066673588335   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 26.178591012954712\n",
      "Epoch: 9   Train loss: 0.4321640116429468   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5000183275568555   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.43578815460205\n",
      "Epoch: 10   Train loss: 0.42563633742736795   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5319723988834181   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.384387254714966\n",
      "Epoch: 11   Train loss: 0.43092863923973507   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5071368634003645   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.444223403930664\n",
      "Epoch: 12   Train loss: 0.44044989530454604   Top1 accuracy: 99.80994152046783   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.51522590925819   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.69654941558838\n",
      "Epoch: 13   Train loss: 0.43099035671231345   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5000008016999005   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.35602569580078\n",
      "Epoch: 14   Train loss: 0.4209511893534521   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49769124998683817   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.11492085456848\n",
      "Epoch: 15   Train loss: 0.42710216482828933   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5011591836374406   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.17817497253418\n",
      "Epoch: 16   Train loss: 0.4343894221629316   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5153624506024589   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.059509754180908\n",
      "Epoch: 17   Train loss: 0.4303780265196025   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5043384377022235   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.16537857055664\n",
      "Epoch: 18   Train loss: 0.4358272180396911   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5172073485558493   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.20610284805298\n",
      "Epoch: 19   Train loss: 0.42308848617021105   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5036158016202046   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.34804677963257\n",
      "Epoch: 20   Train loss: 0.43751389502781873   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5071665174082706   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.40026307106018\n",
      "Epoch: 21   Train loss: 0.43502054681554875   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5140919389083372   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.286081075668335\n",
      "Epoch: 22   Train loss: 0.41852014951887184   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4999610133338393   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.95129370689392\n",
      "Epoch: 23   Train loss: 0.4407878717658115   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49342290229267544   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.901443004608154\n",
      "Epoch: 24   Train loss: 0.44999425200342436   Top1 accuracy: 99.80994152046783   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.5198245097322074   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.762277841567993\n",
      "Epoch: 25   Train loss: 0.4280703294346904   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5074188927112268   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 24.62776780128479\n",
      "Epoch: 26   Train loss: 0.4206445044592807   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4965829899785114   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.077088356018066\n",
      "Epoch: 27   Train loss: 0.4248856204120736   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4997197849708691   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.757757902145386\n",
      "Epoch: 28   Train loss: 0.4236747621618516   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5019919800828074   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.36545753479004\n",
      "Epoch: 29   Train loss: 0.4184212906841646   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4971586237525382   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.705159425735474\n",
      "best epoch: 9, train top1 acc:99.810, top5 acc:100.000; val top1 acc:99.971, top5 acc:100.000, train loss:0.4322, val loss: 0.5000\n",
      "val sub [15]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.49957658707747   Top1 accuracy: 60.058479532163744   Top5 accuracy: 69.72222222222223\n",
      "\tVal loss: 0.9206802709060803   Top1 accuracy: 99.53216374269006   Top5 accuracy: 100.0\n",
      "time consumed: 25.975114583969116\n",
      "Epoch: 1   Train loss: 0.6595439130102682   Top1 accuracy: 99.69298245614036   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5668799469345495   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 24.78919553756714\n",
      "Epoch: 2   Train loss: 0.4993100283090134   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49823042210082563   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 24.78217053413391\n",
      "Epoch: 3   Train loss: 0.4588126690067046   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4786697929365593   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 24.690096616744995\n",
      "Epoch: 4   Train loss: 0.4500161039898967   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47265611597669055   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 24.76107430458069\n",
      "Epoch: 5   Train loss: 0.43607647690856666   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48478248053126866   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 24.762664794921875\n",
      "Epoch: 6   Train loss: 0.4374374880602485   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4678452406187504   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 24.95228147506714\n",
      "Epoch: 7   Train loss: 0.4466205179168467   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46515700569626883   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 24.92082667350769\n",
      "Epoch: 8   Train loss: 0.44207063866289037   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48293556734832405   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.16159462928772\n",
      "Epoch: 9   Train loss: 0.43605931225227335   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45819092162868436   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.118781089782715\n",
      "Epoch: 10   Train loss: 0.4438366274736081   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.486886633767022   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.137349128723145\n",
      "Epoch: 11   Train loss: 0.4317942786286449   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45176534781679073   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 25.133995532989502\n",
      "Epoch: 12   Train loss: 0.4330053317267992   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46027782977673043   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.079187631607056\n",
      "Epoch: 13   Train loss: 0.4447127469101844   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46567349214302867   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.06105375289917\n",
      "Epoch: 14   Train loss: 0.44149314477081186   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4536156430404786   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.055346250534058\n",
      "Epoch: 15   Train loss: 0.43149896698039875   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4608155445397249   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.04800248146057\n",
      "Epoch: 16   Train loss: 0.4402048245333789   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46702743848862005   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.86220645904541\n",
      "Epoch: 17   Train loss: 0.4325862009274332   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4678178722398323   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 24.979537963867188\n",
      "Epoch: 18   Train loss: 0.42701201933866356   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45310007732862617   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 24.988640546798706\n",
      "Epoch: 19   Train loss: 0.42317562685375326   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.463298954984598   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 24.92297863960266\n",
      "Epoch: 20   Train loss: 0.43750486143848355   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46265032486608854   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 24.971584796905518\n",
      "Epoch: 21   Train loss: 0.43057995476917915   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46041242412307803   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "time consumed: 24.922568559646606\n",
      "Epoch: 22   Train loss: 0.42965020335208604   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4532576576310989   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 24.914487838745117\n",
      "Epoch: 23   Train loss: 0.43211523665670765   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4588231402531005   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 24.963215112686157\n",
      "Epoch: 24   Train loss: 0.4292273293113151   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45817269167007757   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 24.976740837097168\n",
      "Epoch: 25   Train loss: 0.4354401171555993   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4579471396772485   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 24.951547622680664\n",
      "Epoch: 26   Train loss: 0.4370621240626999   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47498842655566703   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.989915370941162\n",
      "Epoch: 27   Train loss: 0.4314232783185111   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4642113630186048   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 24.986210346221924\n",
      "Epoch: 28   Train loss: 0.44148699137551045   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4756891683876863   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 24.917483806610107\n",
      "Epoch: 29   Train loss: 0.4333347073423932   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4576073093721044   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 24.894633531570435\n",
      "best epoch: 9, train top1 acc:99.868, top5 acc:100.000; val top1 acc:99.912, top5 acc:100.000, train loss:0.4361, val loss: 0.4582\n",
      "val sub [16]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.370912070162812   Top1 accuracy: 62.675438596491226   Top5 accuracy: 73.66959064327486\n",
      "\tVal loss: 0.9010276780490987   Top1 accuracy: 99.60526315789474   Top5 accuracy: 99.97076023391813\n",
      "time consumed: 26.081626892089844\n",
      "Epoch: 1   Train loss: 0.6660597627623039   Top1 accuracy: 99.70760233918129   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5606861853460122   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.05318832397461\n",
      "Epoch: 2   Train loss: 0.5154478316418609   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4900802068891581   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.99440336227417\n",
      "Epoch: 3   Train loss: 0.4663565191086273   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4639362067158459   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.087198734283447\n",
      "Epoch: 4   Train loss: 0.45067590814933445   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44906743907789043   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.26090097427368\n",
      "Epoch: 5   Train loss: 0.44825619040874015   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44446164596150495   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.10288977622986\n",
      "Epoch: 6   Train loss: 0.45077301875541087   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4401595151563834   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.095073223114014\n",
      "Epoch: 7   Train loss: 0.44846914795755644   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43488402551377725   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.113601207733154\n",
      "Epoch: 8   Train loss: 0.43708458804247674   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43427187448356586   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.852416515350342\n",
      "Epoch: 9   Train loss: 0.4482284305911315   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4401631283829784   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 24.896185398101807\n",
      "Epoch: 10   Train loss: 0.4417237184549633   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43937782341973824   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.984909057617188\n",
      "Epoch: 11   Train loss: 0.4391334801040895   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4369473954041799   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.92224884033203\n",
      "Epoch: 12   Train loss: 0.4412246804836898   Top1 accuracy: 99.78070175438596   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44441179329888864   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "time consumed: 25.112663984298706\n",
      "Epoch: 13   Train loss: 0.4361191432901293   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4319064524787211   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.108966588974\n",
      "Epoch: 14   Train loss: 0.4400132619149504   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43522235158591244   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.0709969997406\n",
      "Epoch: 15   Train loss: 0.44120450204575967   Top1 accuracy: 99.80994152046783   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.4328521781148966   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.100502252578735\n",
      "Epoch: 16   Train loss: 0.44498412223935824   Top1 accuracy: 99.85380116959064   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.4389622614049075   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.03141212463379\n",
      "Epoch: 17   Train loss: 0.44111868538703136   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42997909672776163   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.057939291000366\n",
      "Epoch: 18   Train loss: 0.4329919368028641   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.48262296660601745   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.102710485458374\n",
      "Epoch: 19   Train loss: 0.4394128448084781   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4347581030332554   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.06653070449829\n",
      "Epoch: 20   Train loss: 0.4364337288496787   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4346572432601661   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.96002459526062\n",
      "Epoch: 21   Train loss: 0.43250751373363516   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44345070186414215   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.87140917778015\n",
      "Epoch: 22   Train loss: 0.42990074772932374   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4318437630321547   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.89955472946167\n",
      "Epoch: 23   Train loss: 0.44000611432463105   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4326847721958718   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.999364852905273\n",
      "Epoch: 24   Train loss: 0.4254776628916724   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4285746181917469   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.962018251419067\n",
      "Epoch: 25   Train loss: 0.4540455923442952   Top1 accuracy: 99.61988304093568   Top5 accuracy: 99.88304093567251\n",
      "\tVal loss: 0.5048052698199512   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.065277099609375\n",
      "Epoch: 26   Train loss: 0.44173214484376516   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43568275093335157   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 24.96527934074402\n",
      "Epoch: 27   Train loss: 0.4308316718939452   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.429889944038893   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.99946355819702\n",
      "Epoch: 28   Train loss: 0.4378881096317057   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42863151465940197   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 24.971023559570312\n",
      "Epoch: 29   Train loss: 0.43573109953724154   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43132089993409944   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.962032556533813\n",
      "best epoch: 12, train top1 acc:99.781, top5 acc:100.000; val top1 acc:99.985, top5 acc:100.000, train loss:0.4412, val loss: 0.4444\n",
      "val sub [17]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.431582106135742   Top1 accuracy: 59.45906432748538   Top5 accuracy: 70.84795321637426\n",
      "\tVal loss: 0.9201949259691071   Top1 accuracy: 99.3859649122807   Top5 accuracy: 99.95614035087719\n",
      "time consumed: 25.880934238433838\n",
      "Epoch: 1   Train loss: 0.6775484044998012   Top1 accuracy: 99.53216374269006   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.5740290258014411   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "time consumed: 24.910084009170532\n",
      "Epoch: 2   Train loss: 0.5087913068240149   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.49826406578571475   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.865588665008545\n",
      "Epoch: 3   Train loss: 0.46232801309803073   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47881546564269484   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 24.848870038986206\n",
      "Epoch: 4   Train loss: 0.46175496689757406   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.470099390424483   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.884594202041626\n",
      "Epoch: 5   Train loss: 0.44530580964004784   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4655899276510317   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.938828468322754\n",
      "Epoch: 6   Train loss: 0.44799307825272544   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5037896648833626   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 24.92978000640869\n",
      "Epoch: 7   Train loss: 0.4355560183002238   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46025455730003223   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 24.94431972503662\n",
      "Epoch: 8   Train loss: 0.4455979785375428   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4736613254798086   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 24.943347215652466\n",
      "Epoch: 9   Train loss: 0.4434484447303571   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4581575323963723   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.937360286712646\n",
      "Epoch: 10   Train loss: 0.44012786927278974   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.466291415238241   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.017714262008667\n",
      "Epoch: 11   Train loss: 0.4349190810619042   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46096336789298475   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 24.989370822906494\n",
      "Epoch: 12   Train loss: 0.4250299052188271   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46258964855768525   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.013330698013306\n",
      "Epoch: 13   Train loss: 0.4444450531263798   Top1 accuracy: 99.7953216374269   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4633216981650793   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.0378258228302\n",
      "Epoch: 14   Train loss: 0.4421221790780798   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4572701236309364   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.062244653701782\n",
      "Epoch: 15   Train loss: 0.4272416495440299   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4606818992492051   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.067572116851807\n",
      "Epoch: 16   Train loss: 0.4282065595102589   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.46203097178224933   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "time consumed: 25.079713344573975\n",
      "Epoch: 17   Train loss: 0.433397729407277   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4689188099395462   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "time consumed: 25.073283195495605\n",
      "Epoch: 18   Train loss: 0.432430360139462   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4634590260466637   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.02595329284668\n",
      "Epoch: 19   Train loss: 0.44279936409136006   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4753360873774478   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "time consumed: 25.071597814559937\n",
      "Epoch: 20   Train loss: 0.4364748750513757   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4594772189681293   Top1 accuracy: 99.88304093567251   Top5 accuracy: 99.98538011695906\n",
      "time consumed: 24.988537073135376\n",
      "Epoch: 21   Train loss: 0.43832437667930335   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4510428387867777   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.002947092056274\n",
      "Epoch: 22   Train loss: 0.4324845387573131   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4670412676376209   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.026446104049683\n",
      "Epoch: 23   Train loss: 0.4229726909893995   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4617744227598982   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 24.973186492919922\n",
      "Epoch: 24   Train loss: 0.4218485426833058   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4613701211430176   Top1 accuracy: 99.85380116959064   Top5 accuracy: 99.98538011695906\n",
      "time consumed: 24.784244060516357\n",
      "Epoch: 25   Train loss: 0.4475435889952364   Top1 accuracy: 99.76608187134502   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.47193525949416804   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.123560428619385\n",
      "Epoch: 26   Train loss: 0.42840734934597685   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4530209281988311   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.20612931251526\n",
      "Epoch: 27   Train loss: 0.4275012945222576   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4532983874716954   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.1963951587677\n",
      "Epoch: 28   Train loss: 0.427502429886171   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4581874138430545   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.097951650619507\n",
      "Epoch: 29   Train loss: 0.45181840998038914   Top1 accuracy: 99.73684210526316   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.45917525155502453   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.086374282836914\n",
      "best epoch: 4, train top1 acc:99.883, top5 acc:100.000; val top1 acc:99.927, top5 acc:100.000, train loss:0.4618, val loss: 0.4701\n",
      "val sub [18]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.309743408919775   Top1 accuracy: 66.2719298245614   Top5 accuracy: 75.97953216374269\n",
      "\tVal loss: 0.8677399259561683   Top1 accuracy: 99.64912280701755   Top5 accuracy: 99.98538011695906\n",
      "time consumed: 26.17118549346924\n",
      "Epoch: 1   Train loss: 0.6596321313701875   Top1 accuracy: 99.64912280701755   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.5416565446825753   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.403769969940186\n",
      "Epoch: 2   Train loss: 0.4981576564193469   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4711848300451424   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "time consumed: 25.402916193008423\n",
      "Epoch: 3   Train loss: 0.4639068344357418   Top1 accuracy: 99.80994152046783   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44933033599491007   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.41849660873413\n",
      "Epoch: 4   Train loss: 0.44037070173269127   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43670987908603154   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.428610801696777\n",
      "Epoch: 5   Train loss: 0.4515581761884411   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43705579708194175   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.42337441444397\n",
      "Epoch: 6   Train loss: 0.44149166031887654   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4616885073700843   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.468032360076904\n",
      "Epoch: 7   Train loss: 0.4427952820446059   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42804852563735335   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.421696186065674\n",
      "Epoch: 8   Train loss: 0.44468346691271016   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4297887731713858   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.376232385635376\n",
      "Epoch: 9   Train loss: 0.44984481174346297   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4291399065514057   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.418622493743896\n",
      "Epoch: 10   Train loss: 0.43268164547911864   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42939422109670805   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.393887042999268\n",
      "Epoch: 11   Train loss: 0.43110493226358065   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42625237905491165   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.417453289031982\n",
      "Epoch: 12   Train loss: 0.43784794071961564   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4264372857341989   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.410014390945435\n",
      "Epoch: 13   Train loss: 0.43950408836554367   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.425053103973991   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.417500257492065\n",
      "Epoch: 14   Train loss: 0.4464726285976276   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43937123710649056   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.408759832382202\n",
      "Epoch: 15   Train loss: 0.4437639542490418   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.44143946878394186   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.449275493621826\n",
      "Epoch: 16   Train loss: 0.43691747334965486   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43243055559738336   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.43762469291687\n",
      "Epoch: 17   Train loss: 0.4395267583473384   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4348492237210971   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.481223106384277\n",
      "Epoch: 18   Train loss: 0.44673137096633686   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4237719148571728   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.475979328155518\n",
      "Epoch: 19   Train loss: 0.4749979517961803   Top1 accuracy: 99.45906432748538   Top5 accuracy: 99.89766081871345\n",
      "\tVal loss: 0.49775420260011105   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "time consumed: 25.430845499038696\n",
      "Epoch: 20   Train loss: 0.4332645392557334   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4254295446022212   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.669694185256958\n",
      "Epoch: 21   Train loss: 0.4382478964259053   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42435269955306026   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.39581537246704\n",
      "Epoch: 22   Train loss: 0.44203137636881823   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42445073995673865   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.23154354095459\n",
      "Epoch: 23   Train loss: 0.42980901565816665   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.4263263379621227   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "time consumed: 25.177555799484253\n",
      "Epoch: 24   Train loss: 0.4318032721329851   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42816630197547334   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.140704870224\n",
      "Epoch: 25   Train loss: 0.4371633247325295   Top1 accuracy: 99.92690058479532   Top5 accuracy: 99.98538011695906\n",
      "\tVal loss: 0.42317722589648954   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.178695917129517\n",
      "Epoch: 26   Train loss: 0.4444286957470297   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42103549785781325   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.19373607635498\n",
      "Epoch: 27   Train loss: 0.4268303978861424   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.42213066227254814   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.075427055358887\n",
      "Epoch: 28   Train loss: 0.43795840137186104   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.43897356537350435   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 24.965809106826782\n",
      "Epoch: 29   Train loss: 0.4371261725648802   Top1 accuracy: 99.78070175438596   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.4293445103001176   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 24.906906843185425\n",
      "best epoch: 4, train top1 acc:99.883, top5 acc:100.000; val top1 acc:99.927, top5 acc:100.000, train loss:0.4404, val loss: 0.4367\n",
      "val sub [19]\n",
      "data_train.shape, data_val.shape (7296000, 128) (7680000, 128)\n",
      "ConvNet_avgPool_share(\n",
      "  (spatialConv): Conv2d(1, 16, kernel_size=(128, 1), stride=(1, 1))\n",
      "  (timeConv): Conv2d(1, 16, kernel_size=(1, 30), stride=(1, 1))\n",
      "  (avgpool): AvgPool2d(kernel_size=(1, 15), stride=(1, 15), padding=0)\n",
      ")\n",
      "Total number of parameters: 2560\n",
      "Epoch: 0   Train loss: 2.762145974482709   Top1 accuracy: 53.94736842105263   Top5 accuracy: 66.33040935672514\n",
      "\tVal loss: 0.966402280400371   Top1 accuracy: 99.63450292397661   Top5 accuracy: 100.0\n",
      "time consumed: 25.83248281478882\n",
      "Epoch: 1   Train loss: 0.7484512015392906   Top1 accuracy: 99.66374269005848   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.4585740981046219   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.38617444038391\n",
      "Epoch: 2   Train loss: 0.5473378584747426   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3825745734206417   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.41264319419861\n",
      "Epoch: 3   Train loss: 0.4802738910007198   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35435016740832415   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.45891809463501\n",
      "Epoch: 4   Train loss: 0.47343147986116463   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3480367121989267   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.391979217529297\n",
      "Epoch: 5   Train loss: 0.4593460674000065   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.34037410489648406   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.393850564956665\n",
      "Epoch: 6   Train loss: 0.4679070080232899   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3374649010032241   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.420865535736084\n",
      "Epoch: 7   Train loss: 0.44562372321273847   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.36949957837486824   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "time consumed: 25.462463855743408\n",
      "Epoch: 8   Train loss: 0.44683176226783217   Top1 accuracy: 99.98538011695906   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3356132977887204   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.481085538864136\n",
      "Epoch: 9   Train loss: 0.45238533807776826   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33224854308959334   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.582345008850098\n",
      "Epoch: 10   Train loss: 0.44705947658471895   Top1 accuracy: 99.85380116959064   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33194592185536326   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.02012538909912\n",
      "Epoch: 11   Train loss: 0.44648679951478165   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.332621866673754   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.04010033607483\n",
      "Epoch: 12   Train loss: 0.47903712172257273   Top1 accuracy: 99.72222222222223   Top5 accuracy: 99.97076023391813\n",
      "\tVal loss: 0.33408382491410127   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.29607343673706\n",
      "Epoch: 13   Train loss: 0.4503828347252126   Top1 accuracy: 99.8391812865497   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3284478963989961   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.222025394439697\n",
      "Epoch: 14   Train loss: 0.44149141789179797   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.324589814794691   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.301873922348022\n",
      "Epoch: 15   Train loss: 0.4402123518854554   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.32888327207830215   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "time consumed: 25.320439100265503\n",
      "Epoch: 16   Train loss: 0.4510866324281135   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33553349248498504   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.321921825408936\n",
      "Epoch: 17   Train loss: 0.4535339826728865   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3378137784046039   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.304848432540894\n",
      "Epoch: 18   Train loss: 0.45406341064743133   Top1 accuracy: 99.89766081871345   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3273477139528732   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.318539142608643\n",
      "Epoch: 19   Train loss: 0.45486738876989713   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33205773267481065   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.321524381637573\n",
      "Epoch: 20   Train loss: 0.4494375295457784   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.32878990863498886   Top1 accuracy: 99.97076023391813   Top5 accuracy: 100.0\n",
      "time consumed: 25.312097787857056\n",
      "Epoch: 21   Train loss: 0.44620412962827066   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.35279842627327346   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.319394826889038\n",
      "Epoch: 22   Train loss: 0.44361590589696204   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33493219838853466   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.265938997268677\n",
      "Epoch: 23   Train loss: 0.46534248410958295   Top1 accuracy: 99.82456140350877   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3447974384353872   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.317599534988403\n",
      "Epoch: 24   Train loss: 0.45379156309958785   Top1 accuracy: 99.92690058479532   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.322711981353704   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.330077171325684\n",
      "Epoch: 25   Train loss: 0.4430110966950132   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.33359444176244457   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.29852557182312\n",
      "Epoch: 26   Train loss: 0.44759012070315624   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.32615992008594047   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.299686908721924\n",
      "Epoch: 27   Train loss: 0.4432123040246685   Top1 accuracy: 99.91228070175438   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3279664322995303   Top1 accuracy: 99.95614035087719   Top5 accuracy: 100.0\n",
      "time consumed: 25.314960479736328\n",
      "Epoch: 28   Train loss: 0.4491775024529786   Top1 accuracy: 99.86842105263158   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.32373273224509946   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.313488245010376\n",
      "Epoch: 29   Train loss: 0.46138536991083134   Top1 accuracy: 99.88304093567251   Top5 accuracy: 100.0\n",
      "\tVal loss: 0.3244550707396011   Top1 accuracy: 99.94152046783626   Top5 accuracy: 100.0\n",
      "time consumed: 25.317700147628784\n",
      "best epoch: 8, train top1 acc:99.985, top5 acc:100.000; val top1 acc:99.971, top5 acc:100.000, train loss:0.4468, val loss: 0.3356\n",
      "train top1 mean: 99.872, train top1 std: 0.052; val top1 mean: 99.939, val top1 std: 0.048\n"
     ]
    }
   ],
   "source": [
    "# Train the cross-validation model\n",
    "cl_model = cl_sster(n_folds=n_subs, epochs_pretrain=epochs_pretrain, data_type='simulation')\n",
    "cl_model.load_data(data, n_points) # fs: sampling rate\n",
    "cl_model.train_cl_sster()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\0\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\1\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\2\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\3\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\4\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\5\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\6\\checkpoint_0029.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\0_NCCLab\\ContrastiveLearningForEEG\\Code\\api_development\\v3\\postprocessing_utils.py:76: RuntimeWarning: invalid value encountered in divide\n",
      "  corrmat = cov / (x_grid.transpose() * y_grid.transpose())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\7\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\8\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\9\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\10\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\11\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\12\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\13\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\14\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\15\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\16\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\17\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\18\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\19\\checkpoint_0029.pth.tar\n"
     ]
    }
   ],
   "source": [
    "# Get the corresponding dimensions in each training fold\n",
    "correspondDims_fold, corr_mean_fold = cl_model.get_correspond_dims(n_folds=n_subs, out=out, calc_dims=inds_cluster_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\0\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\1\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\2\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\3\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\4\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\5\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\6\\checkpoint_0029.pth.tar\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Windows\\anaconda3\\envs\\cl_sster_env4\\Lib\\site-packages\\numpy\\lib\\function_base.py:2897: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\7\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\8\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\9\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\10\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\11\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\12\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\13\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\14\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\15\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\16\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\17\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\18\\checkpoint_0029.pth.tar\n",
      "checkpoint: results/simulation/timeLen30_wd0.100000_epochs30_tfLen30_avgPool15_timeStep15.000_cv\\19\\checkpoint_0029.pth.tar\n",
      "isc train mean, std: \n",
      "[0.34136128] [0.01157034]\n",
      "isc val mean, std: \n",
      "[0.34090763] [0.01122743]\n"
     ]
    }
   ],
   "source": [
    "# Calculate training and validation ISC in each fold\n",
    "n_folds = n_subs\n",
    "n_per = int(n_subs // n_folds)\n",
    "isc_train_folds = np.zeros((n_folds, n_subs, n_clusters)) - 2.\n",
    "isc_val_folds = np.zeros((n_folds, n_clusters))\n",
    "\n",
    "for val_fold in range(n_folds):\n",
    "    if val_fold < n_folds-1:\n",
    "        val_sub = np.arange(val_fold*n_per, (val_fold+1)*n_per)\n",
    "    else:\n",
    "        val_sub = np.arange(val_fold*n_per, n_subs)\n",
    "    train_sub = list(set(np.arange(n_subs)) - set(val_sub))\n",
    "    sub_order = np.concatenate((train_sub, val_sub))\n",
    "    \n",
    "    # Note that out will be overwritten here (for out of the cl_model_all)\n",
    "    out, n_points_cum = cl_model.get_hidden(val_fold)\n",
    "    out = out[sub_order,:,:]\n",
    "    out_train_corr_mean, out_val_corr_mean = calc_isc(out.transpose(2,1,0), n_points_cum, len(train_sub))\n",
    "    \n",
    "    isc_train_folds[val_fold, train_sub, :] = out_train_corr_mean[correspondDims_fold[val_fold],:].transpose()\n",
    "    isc_val_folds[val_fold, :] = out_val_corr_mean[correspondDims_fold[val_fold]].squeeze()\n",
    "    \n",
    "isc_train_mean = np.zeros((n_subs, n_clusters))\n",
    "for sub in range(n_subs):\n",
    "    for dim in range(n_clusters):\n",
    "        isc_train_mean[sub,dim] = np.mean(isc_train_folds[:,sub,dim][isc_train_folds[:,sub,dim]!=-2], axis=0)\n",
    "isc_train_std = np.std(isc_train_mean, axis=0)\n",
    "isc_train_mean = np.mean(isc_train_mean, axis=0)\n",
    "print('isc train mean, std: ')\n",
    "print(isc_train_mean, isc_train_std)\n",
    "\n",
    "isc_val_mean = np.mean(isc_val_folds, axis=0)\n",
    "isc_val_std = np.std(isc_val_folds, axis=0)\n",
    "print('isc val mean, std: ')\n",
    "print(isc_val_mean, isc_val_std)\n",
    "sio.savemat(os.path.join(cl_model.save_dir, 'isc.mat'), {'isc_train': isc_train_mean, 'isc_val': isc_val_folds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "reordered validation mean, std:\n",
      "[0.34090763] [0.01122743]\n"
     ]
    }
   ],
   "source": [
    "inds_cluster_reorder = np.argsort(isc_val_mean)[::-1]\n",
    "print(inds_cluster_reorder)\n",
    "\n",
    "print('reordered validation mean, std:')\n",
    "print(isc_val_mean[inds_cluster_reorder], isc_val_std[inds_cluster_reorder])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate data covariance for spatial activation\n",
    "data_cov = np.zeros((data.shape[-1], data.shape[-1]))\n",
    "for i in range(n_subs):\n",
    "    data_cov = data_cov + np.dot(data[i,:,:].transpose(), data[i,:,:])\n",
    "data_cov = data_cov / n_subs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "odict_keys(['spatialConv.weight', 'spatialConv.bias', 'timeConv.weight', 'timeConv.bias'])\n",
      "(16, 128) (16, 30)\n",
      "Temporal filter: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Windows\\AppData\\Local\\Temp\\ipykernel_22856\\3058084359.py:10: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  time_inds = int(inds_cluster_max // 16)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial activation: 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x100 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the filters\n",
    "state_dict = torch.load(os.path.join(cl_model_allData.save_dir, '0', 'checkpoint_%04d.pth.tar' % (epochs_pretrain-1)))['state_dict']\n",
    "print(state_dict.keys())\n",
    "\n",
    "spatialWeight = torch.squeeze(state_dict['spatialConv.weight']).cpu().numpy()\n",
    "timeWeight = torch.squeeze(state_dict['timeConv.weight']).cpu().numpy()\n",
    "print(spatialWeight.shape, timeWeight.shape)\n",
    "\n",
    "n_timeFilters, n_spatialFilters = timeWeight.shape[0], spatialWeight.shape[0]\n",
    "time_inds = int(inds_cluster_max // 16)\n",
    "spatial_inds = np.mod(inds_cluster_max, 16)\n",
    "if isinstance(time_inds, int):\n",
    "    time_inds, spatial_inds = [time_inds], [spatial_inds]\n",
    "\n",
    "timeFilterLen = timeWeight.shape[1]\n",
    "f = fs * np.arange(timeFilterLen) / timeFilterLen\n",
    "for i in range(len(time_inds)):\n",
    "    print('Temporal filter: %d' % i)\n",
    "    plt.figure(figsize=(12,2))\n",
    "    sp = np.abs(np.fft.fft(timeWeight[time_inds[i], ::-1]))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(np.arange(0,1/128*30,1/128), timeWeight[time_inds[i]], 'k')\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Time/ms')\n",
    "    plt.title('Temporal filter')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(f[f<=50], sp[f<=50], 'k')\n",
    "    plt.yticks([])\n",
    "    plt.xlabel('Frequency/Hz')\n",
    "    plt.title('Frequency response')\n",
    "    plt.show()\n",
    "\n",
    "for i in range(len(spatial_inds)):\n",
    "    print('Spatial activation: %d' % i)    \n",
    "    spatialActivation = np.dot(data_cov, spatialWeight[spatial_inds[i],:].transpose()).transpose()\n",
    "    plt.figure(figsize=(5,1))\n",
    "    plt.imshow(spatialActivation, aspect='auto')\n",
    "    colorlim = np.max(np.abs(spatialActivation))\n",
    "    plt.clim([-colorlim, colorlim])\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
